{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with Google Gen AI. \n",
    "\n",
    "Let's check that your `GOOGLE_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The best place to see Orcas in the US is **the San Juan Islands in Washington State**.\n",
       "\n",
       "Here's why:\n",
       "\n",
       "*   **Resident Orca Populations:** The San Juan Islands are home to the Southern Resident Killer Whale population, which includes three distinct pods: J, K, and L. These orcas are known for their predictable movements and are frequently sighted in the waters around the islands.\n",
       "*   **Abundant Prey:** The primary food source for these resident orcas is Chinook salmon, which are abundant in the Salish Sea. This creates a reliable feeding ground for the whales.\n",
       "*   **Clear Waters:** The waters in the San Juan Islands are relatively clear, offering excellent visibility for whale watching.\n",
       "*   **Established Whale Watching Industry:** There's a well-developed and responsible whale watching industry in the area, with many operators dedicated to ethical viewing practices.\n",
       "\n",
       "**When to go:**\n",
       "\n",
       "The prime whale watching season for the Southern Resident Orcas in the San Juan Islands is typically from **late May through September**. However, sightings can occur outside of this window, and other whale species like transient orcas (Bigg's killer whales) are present year-round.\n",
       "\n",
       "**Important Considerations for Orca Watching in the San Juan Islands:**\n",
       "\n",
       "*   **Responsible Whale Watching:** It's crucial to choose tour operators who follow strict guidelines to minimize disturbance to the whales. Look for companies that maintain a safe distance, avoid sudden movements, and turn off their engines when near the animals.\n",
       "*   **Respect the Wildlife:** Always follow the instructions of your captain and crew. Never try to feed or touch the whales.\n",
       "*   **Other Marine Life:** While orcas are the main draw, you're also likely to see other incredible marine life, including Minke whales, humpback whales, seals, sea lions, porpoises, and a variety of seabirds.\n",
       "\n",
       "**Other potential, though less consistent, places to see Orcas in the US:**\n",
       "\n",
       "*   **Alaska:** Particularly in Southeast Alaska (e.g., Glacier Bay, Juneau, Sitka), transient orcas are frequently seen, often in conjunction with whale watching tours focused on humpbacks. While you can see orcas here, the San Juan Islands offer a more reliable chance of seeing the *resident* populations.\n",
       "*   **Hawaii:** Transient orcas are sometimes spotted in Hawaiian waters, but these sightings are much rarer and less predictable than in the Pacific Northwest.\n",
       "\n",
       "**In summary, if your primary goal is to see Orcas in the US, the San Juan Islands of Washington State are your best bet.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.5-flash-lite',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 18 multiplied by 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'b': 3, 'a': 18},\n",
       "  'id': 'f8bc7657-8454-4e3a-860a-50b8112c6a7b',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) to address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='763c2447-d340-4983-b864-53d744060ff0'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='147253c7-e605-4050-890b-5dc9386e0d72'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='c8a11d5c-4e07-4e52-8daa-c0497e43409b')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Node for generating a contextual answer after the tool call\n",
    "def answer_llm(state: MessagesState):\n",
    "    # The LLM sees the full message history, including the tool result\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"answer_llm\", answer_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", \"answer_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Are you good at math ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can help with basic math operations like multiplication. What do you need help with?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Are you good at math ?\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 19 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (d6382aaa-0ef9-4d5e-97d3-3593a717a729)\n",
      " Call ID: d6382aaa-0ef9-4d5e-97d3-3593a717a729\n",
      "  Args:\n",
      "    b: 3\n",
      "    a: 19\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "19 multiplied by 3 is 57.\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 19 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
